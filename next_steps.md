## Next Steps
1. clone notebook and set up "query" corpora in brat
2. train dummy models with most promising candidates to learn training procedures
    - stanford (high precision, low recall)
    - spacy
    - CONLL Shared Task Corpora: https://gist.github.com/JackNhat/0dc0b57b248df1b970a0d64475b31580
3. research improved preprocessing
    - handling bulleted lists in preprocessing
    - look at performance of upstream models in spacy and stanford (part-of-speech and parsing)
4. research more targeted corpora 
    - https://arxiv.org/pdf/1705.06123.pdf
5. set up brat server with larger sets labeled by each tool (Rob to help)
6. schedule "correction" sessions with team
7. Rob to share deduped sample set for labeling
